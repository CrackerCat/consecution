MAYBE USE KYOTO CABINET FOR ANY PERSISTANCE NEEDS

* A consecutor is an abstraction designed to be run on one machine either
  in different processes or in different threads.  This means we don't
  need the tcp layer for communication and speeds things up.  On
  initialization, the user can specify either process or thread
  architecture.  Note that this can be switched with one param change.

* Consecutors must have one and only one input stream.  The following
  options are provided:
      - Programatic manually fed with:
          - consecutor.up(); consecutor.push(item); consecutor.down()
          - there is an alias to .push(item) named .append(item) so that a 
            consecutor can be used as an output container for antother
            consecutor.
      - Programatic Iterator fed:
          - consecutor.produce_from_iterable(iterable)  # shuts down when done
      - Pyzmq fed:
          - consecutor.up(); consecutor.produce_from_tcp(uri); consecutor.down()
      - REST fed:
          - consecutor.up(); consecutor.produce_from_http(uri): consecutor.down()
      - stdin fed:
          - consecutor.up()  # terminates when stdin is done

      

* Non programatically fed producers have a method for adding cli args to script.
  This will add appropriate command-line arguments for running a single consecutor
  as a unix executable.  For TCP or REST fed servers, uri information can be
  specified.  Other consecutor configuration params can also be set.  Optionally
  these settings can be read from a configuration file, also referenced in the
  cli.
    - consecutor.expose_cli()

* Maybe consecutor can registor named output containers
    - output containers can be anything with a .append(value) method.
    - syntax can be something like consecutor.register_output(name, container)



* Work-flow is:
    - Define nodes using node classes
    - Wire node up with DSL
    - pass any node into the consecutor constructor
    - start the consecutor


* Wiring happens similar to the first incarnation.  Except that nodes are
  connected by zmp push/pull sockets.  These sockets offer automatic
  round-robin and merging capabilities, and they respect HWM.  There is a one-
  to-one correspondence between the visualization edges I create and the
  socket URIs that are needed.  I think I might want to make a directory
  structure as follows for a consecution project
    ./.consecution/
        consecutor_id_1/
            acker_db.kyoto
            pid_files/
            socket_files/
    .
    .
    .

  Maybe there is a consecution cli command that forecibly removes a consecution
  directory by making sure all the pids are killed, and directories removed.
  Maybe each producer exposes a kill socket into which a kill signal can be
  sent that then propagates down the DAG with a timeout before killing the
  pid(s). When starting a consecutor, a warning will get printed to stderr
  indicating there are consecutor files at this location. The .consecution path
  can be set fro cli or config file, but defaults to `pwd`/.consecution.




* Items can wrap values as they travel through nodes.  Nodes can handle either
  items or non-wrapped values.  Items enable tracking, but result in a
  performance hit.  I think I want to look into kyoto-cabinet and redis as
  acker persistance layers.

  - when an item is created, it is registered with the acker
  - when it is acked or failed, it is also registered with the acker
  - acked items dissappear from the acker

* The acker can either be in-memory or on-disk, depending on consecutor
  configuration.  Consecutor can also be configured to store input items.
  These items can be stored in memory or persisted to disk so that they
  can be replayed into the consecutor on failure.

* Node definition

class BaseNode(object):
    def initialize(self):
        # explicitly not putting this code in __init__ because I want
        # it to be called explicitly when wiring up nodes into a dag.
        # define attributes such as upstream, downstream, consecutor, etc.
        pass

    def new_item(self):
        # this is a factory method for items
        pass

    def set_num_workers(self, n_workers=1):
        # this node gets round-robin
        pass

    def push(self, item):
        # this acks and pushes an item down-stream
        pass

    def write(self, container_name, item):
        # allows writing to consecutor-registered outputs

    def ack(self, item):
        # this acks an item in the node
        pass

    def fail(self, item):
        # this fails an item in the node
        pass

    def connect_with(self, upstream_uri=None, downstream_uri=None):
        # uris are automatically generated, but his allows you
        # to set custom uri's in case you want nodes to talk
        # to nodes in another machine for part of the computation
        # Maybe use case for this is to be invoked in inherited class
        # constructor

    def _a_bunch_of_hidden_methods_for_wiring_etc():
        pass



class MyNode(BaseNode):
    def __init__(self, *args, **kwargs):
        # any state initialization you want done happens here.
        pass

    def process(self, item):
        # code for processing single tuple
        pass

    def end(self):
        # any clean up code you want to run goes here
        pass




#######################################################################
Maybe the consecutor runs its own pull socket that listens for each
node to come alive.  Producer process won't start until all nodes are
up and running.

Maybe each node polls to sockets: it's input socket and a heartbeat socket.
The consecutor will send heartbeats to each node and supervise them.  But
that might not work for long running processes.  Unless the user specifies
a node timout.  Maybe the hearbeat frequency is related to this time.
Maybe each edge is brokered so that any node can be restarted if needed.










